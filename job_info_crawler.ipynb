{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efc08c0f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "import threading\n",
    "import queue\n",
    "import random\n",
    "import datetime\n",
    "import os\n",
    "import urllib3\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from urllib.error import URLError, HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "from config.assistant import *\n",
    "from config.site_config import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "request_headers = {\n",
    "    'User-Agent': ('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
    "                   '(KHTML, like Gecko) Chrome/68.0.3440.75 Safari/537.36'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07f7721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_group = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f630935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dictionary(job_company, company_link, job_posting, posting_link):\n",
    "    global job_group\n",
    "    \n",
    "    # 신규 회사명 인입\n",
    "    if not job_company in job_group:    \n",
    "        job_group[job_company] = []\n",
    "    \n",
    "    for company in job_group[job_company]:\n",
    "        if company['title'] == job_posting:    # 채용공고명 - 중복\n",
    "            break\n",
    "    else:\n",
    "        job_group[job_company].append({'company': job_company, \\\n",
    "                                       'company_link': company_link, \\\n",
    "                                       'title': job_posting, \\\n",
    "                                       'title_link': posting_link, \\\n",
    "                                       'title_idx': len(job_group[job_company]), \\\n",
    "                                       'input_date': datetime.date.today().isoformat(), \\\n",
    "                                       'status': 'wait'\n",
    "                                      })\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07d6187e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering_company_name(job_company):\n",
    "    \n",
    "    # 회사명 - ()괄호 안의 모든 단어 제거\n",
    "    company_re = re.search('\\(.*\\)', job_company)\n",
    "    if company_re:\n",
    "        str_filtering = job_company[company_re.span()[0]:company_re.span()[1]]\n",
    "        job_company = job_company.replace(str_filtering, '')\n",
    "        \n",
    "    # 회사명 - 특정 단어 제거\n",
    "    for remove_word in remove_words:\n",
    "        if remove_word in job_company:\n",
    "            job_company = job_company.replace(remove_word, '')\n",
    "    \n",
    "    # 회사명 - 완전히 일치하는 회사명 리스트 필터링\n",
    "    if job_company in filter_list_company_name:\n",
    "        return 0, \"none\"\n",
    "    \n",
    "    # 회사명 - 특정 단어가 포함되어 있는 회사 필터링\n",
    "    for remove_word in filter_list_company_name_part:\n",
    "        if remove_word in job_company:\n",
    "            return 0, \"none\"\n",
    "\n",
    "    return 1, job_company"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5e5d0c",
   "metadata": {},
   "source": [
    "### 사람인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee70547b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMAGE RECOGNITION: 19\n",
      "------------\n",
      "Elapsed time is 28.312422513961792 seconds.\n"
     ]
    }
   ],
   "source": [
    "tic()\n",
    "\n",
    "for search_word in search_words:\n",
    "\n",
    "    item_count = 0\n",
    "    current_page = 1\n",
    "    search_result_num = 0\n",
    "\n",
    "    # =======================================================================================\n",
    "    \n",
    "    # 검색 결과 리스트 페이지 별 확인\n",
    "    \n",
    "    search_loop = True\n",
    "    while True:\n",
    "        search_link = f'https://www.saramin.co.kr/zf_user/search/recruit'\\\n",
    "            + f'?search_area=main'\\\n",
    "            + f'&search_done=y'\\\n",
    "            + f'&search_optional_item=n'\\\n",
    "            + f'&searchType=search'\\\n",
    "            + f'&recruitSort=relation'\\\n",
    "            + f'&searchword={search_word}'\\\n",
    "            + f'&recruitPage={current_page}'\\\n",
    "            + f'&recruitPageCount={page_view_items}'\\\n",
    "            + f'&company_cd={company_cd}'\\\n",
    "            + f'&mainSearch=y'\n",
    "        response = requests.get(search_link, headers=request_headers, verify=False)\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        dom = etree.HTML(str(soup))\n",
    "        \n",
    "        # =======================================================================================\n",
    "        \n",
    "        # 검색단어 리스트 별 검색 결과 개수, 검색 결과가 없으면 종료\n",
    "        \n",
    "        try:\n",
    "            num_str = dom.xpath('//*[@id=\"recruit_info\"]/div[1]/span')[0].text\n",
    "            search_result_num = int(re.sub(r'[^0-9]', '', num_str))\n",
    "        except:\n",
    "            break\n",
    "        finally:\n",
    "            if current_page == 1:\n",
    "                print(f'{search_word}: {search_result_num}')\n",
    "\n",
    "        # =======================================================================================\n",
    "        \n",
    "        current_page += 1\n",
    "\n",
    "        \n",
    "        page_items = len(soup.find_all('h2', attrs={'class': 'job_tit'}))\n",
    "\n",
    "        # 해당 페이지 리스트 (1 ~ 100)\n",
    "        for i in range(1, page_items+1):\n",
    "            elements = soup.select(f'div.content > div:nth-child({i})')[0]\n",
    "\n",
    "            # 회사명\n",
    "            job_company = elements.find('a', attrs={'class': 'track_event data_layer'}).text\n",
    "            filtering_result = filtering_company_name(job_company)\n",
    "            if filtering_result[0] == 0:\n",
    "                continue\n",
    "            else:\n",
    "                job_company = filtering_result[1]\n",
    "\n",
    "            # 채용공고명\n",
    "            job_posting = elements.find('a', attrs={'class': 'data_layer'})['title']\n",
    "\n",
    "            # 채용공고 링크\n",
    "            posting_link = base_link_saram + elements.find('a', attrs={'class': 'data_layer'})['href']\n",
    "\n",
    "            # 회사 링크\n",
    "            company_link = base_link_saram + elements.find('a', attrs={'class': 'track_event data_layer'})['href']\n",
    "\n",
    "            # Dictionary에 저장\n",
    "            save_dictionary(job_company, company_link, job_posting, posting_link)\n",
    "\n",
    "            item_count += 1\n",
    "\n",
    "print(\"------------\")\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e50235f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13f9a1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "nCnt = 0\n",
    "for i in job_group:\n",
    "    for j in job_group[i]:\n",
    "        nCnt += 1\n",
    "print(nCnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af43b062",
   "metadata": {},
   "source": [
    "### 잡코리아"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eff33be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "컴퓨터비전: 1105\n",
      "COMPUTER VISION: 110\n",
      "영상처리: 1087\n",
      "IMAGE PROCESSING: 58\n",
      "딥러닝: 1154\n",
      "DEEP LEARNING: 188\n",
      "머신러닝: 1750\n",
      "MACHINE LEARNING: 1754\n",
      "이미지인식: 129\n",
      "IMAGE RECOGNITION: 22\n",
      "이미지분석: 2220\n",
      "IMAGE ANALYSIS: 23\n",
      "VISION AI: 254\n",
      "OPENCV: 144\n",
      "Elapsed time is 537.1458041667938 seconds.\n"
     ]
    }
   ],
   "source": [
    "# 잡코리아\n",
    "# 저장된 키워드 별 검색\n",
    "\n",
    "tic()\n",
    "for search_word in search_words:\n",
    "\n",
    "    item_count = 0\n",
    "    current_page = 1\n",
    "    \n",
    "    # 검색 결과 리스트 페이지 별 확인\n",
    "    search_loop = True\n",
    "    while(search_loop):\n",
    "        search_link = f'https://www.jobkorea.co.kr/Search/' \\\n",
    "                    +f'?stext={search_word}' \\\n",
    "                    +f'&tabType=recruit&Page_No={current_page}'\n",
    "\n",
    "        response = requests.get(search_link, headers=request_headers, verify=False)\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "\n",
    "\n",
    "        page_items = len(soup.find_all('a', attrs={'class': 'title dev_view'}))\n",
    "        \n",
    "        if page_items == 0:\n",
    "            search_loop = False\n",
    "        else:\n",
    "            for i in range(0, page_items):\n",
    "                # 회사명\n",
    "                job_company = soup.find_all('a', attrs={'class': 'name dev_view'})[i].text\n",
    "                filtering_result = filtering_company_name(job_company)\n",
    "                if filtering_result[0] == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    job_company = filtering_result[1]\n",
    "                \n",
    "                # 회사 링크\n",
    "                company_link = base_link_korea + soup.find_all('a', attrs={'class': 'name dev_view'})[i]['href']\n",
    "                \n",
    "                # 채용공고\n",
    "                job_posting = soup.find_all('a', attrs={'class': 'title dev_view'})[i].text\n",
    "                job_posting = job_posting.replace('\\r\\n', '')\n",
    "                job_posting = job_posting.strip()\n",
    "\n",
    "                # 채용공고 링크\n",
    "                posting_link = base_link_korea + soup.find_all('a', attrs={'class': 'title dev_view'})[i]['href']\n",
    "\n",
    "                # Dictionary에 저장\n",
    "                save_dictionary(job_company, company_link, job_posting, posting_link)\n",
    "                \n",
    "                item_count += 1\n",
    "        current_page += 1\n",
    "    print(f'{search_word}: {item_count}')\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50559ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5688"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81c00a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12694\n"
     ]
    }
   ],
   "source": [
    "nCnt = 0\n",
    "for i in job_group:\n",
    "    for j in job_group[i]:\n",
    "        nCnt += 1\n",
    "print(nCnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abba220b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb812a22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96304fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019232c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52011d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "061b6b35",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# JSON 파일 쓰기\n",
    "tf = open(file_path, 'w')\n",
    "json.dump(job_group, tf)\n",
    "tf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "996ed0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5494\n"
     ]
    }
   ],
   "source": [
    "# JSON 파일 불러오기\n",
    "with open(file_path, 'r') as file:\n",
    "    job_group = json.load(file)\n",
    "print(len(job_group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255b3732",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackerrank",
   "language": "python",
   "name": "hackerrank"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
