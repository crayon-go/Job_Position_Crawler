{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efc08c0f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "import threading\n",
    "import queue\n",
    "import random\n",
    "import datetime\n",
    "import os\n",
    "import urllib3\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from urllib.error import URLError, HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "from config.assistant import *\n",
    "from config.site_config import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "request_headers = {\n",
    "    'User-Agent': ('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
    "                   '(KHTML, like Gecko) Chrome/68.0.3440.75 Safari/537.36'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07f7721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_group = {}\n",
    "\n",
    "with open(filter_list_company_name_path) as f:\n",
    "    filter_list_company_name = f.read().splitlines()\n",
    "with open(filter_list_company_name_part_path) as f:\n",
    "    filter_list_company_name_part = f.read().splitlines()\n",
    "\n",
    "with open(filter_list_posting_region_path) as f:\n",
    "    filter_list_posting_region = f.read().splitlines()\n",
    "with open(filter_list_posting_name_part_path) as f:\n",
    "    filter_list_posting_name_part = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f630935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dictionary(job_company, company_link, posting_str, posting_link):\n",
    "    global job_group\n",
    "    \n",
    "    # 신규 회사명 인입\n",
    "    if not job_company in job_group:    \n",
    "        job_group[job_company] = []\n",
    "    \n",
    "    for company in job_group[job_company]:\n",
    "        if company['title'] == posting_str:    # 채용공고명 - 중복\n",
    "            break\n",
    "    else:\n",
    "        job_group[job_company].append({'company': job_company, \\\n",
    "                                       'company_link': company_link, \\\n",
    "                                       'title': posting_str, \\\n",
    "                                       'title_link': posting_link, \\\n",
    "                                       'title_idx': len(job_group[job_company]), \\\n",
    "                                       'input_date': datetime.date.today().isoformat(), \\\n",
    "                                       'status': 'wait'\n",
    "                                      })\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e7d4e8",
   "metadata": {},
   "source": [
    "### 회사명 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07d6187e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering_company_name(job_company):\n",
    "\n",
    "    # 회사명 - 특정 단어 제거\n",
    "    for remove_word in remove_words:\n",
    "        if remove_word in job_company:\n",
    "            job_company = job_company.replace(remove_word, '')\n",
    "            \n",
    "    # 회사명 - ()괄호 안의 모든 단어 제거\n",
    "    company_re = re.search('\\(.*\\)', job_company)\n",
    "    if company_re:\n",
    "        str_filtering = job_company[company_re.span()[0]:company_re.span()[1]]\n",
    "        job_company = job_company.replace(str_filtering, '')\n",
    "        \n",
    "    # 회사명 - 완전히 일치하는 회사명 리스트 필터링\n",
    "    if job_company in filter_list_company_name:\n",
    "        return 0, \"none\"\n",
    "    \n",
    "    # 회사명 - 특정 단어가 포함되어 있는 회사 필터링\n",
    "    for remove_word in filter_list_company_name_part:\n",
    "        if remove_word in job_company:\n",
    "            return 0, \"none\"\n",
    "\n",
    "    return 1, job_company"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80008f12",
   "metadata": {},
   "source": [
    "### 채용공고명 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d40a54be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering_posting_name(posting_str):\n",
    "\n",
    "    # 지역명이 포함되는 경우 탈락\n",
    "    for remove_word in filter_list_posting_region:\n",
    "        if remove_word in posting_str:\n",
    "            return 0, \"none\"\n",
    "\n",
    "    # 특정 단어가 포함되는 경우 탈락\n",
    "    for remove_word in filter_list_posting_name_part:\n",
    "        if remove_word in posting_str:\n",
    "            return 0, \"none\"\n",
    "\n",
    "    return 1, posting_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad8dfae",
   "metadata": {},
   "source": [
    "### JSON 파일 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76bd5357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5416\n"
     ]
    }
   ],
   "source": [
    "# JSON 파일 불러오기\n",
    "with open(file_path, 'r') as file:\n",
    "    job_group = json.load(file)\n",
    "print(len(job_group))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5e5d0c",
   "metadata": {},
   "source": [
    "### 사람인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee70547b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "컴퓨터비전: 1170\n",
      "COMPUTER VISION: 995\n",
      "영상처리: 1043\n",
      "IMAGE PROCESSING: 275\n",
      "딥러닝: 1021\n",
      "DEEP LEARNING: 1021\n",
      "머신러닝: 1378\n",
      "MACHINE LEARNING: 1370\n",
      "이미지인식: 189\n",
      "IMAGE RECOGNITION: 19\n",
      "이미지분석: 688\n",
      "IMAGE ANALYSIS: 17\n",
      "VISION AI: 743\n",
      "OPENCV: 271\n",
      "로봇비전: 192\n",
      "인공지능: 3699\n",
      "ARTIFICIAL INTELLIGENCE: 21\n",
      "AI기술: 2549\n",
      "--------------------------------------------\n",
      "Elapsed time is 969.0083892345428 seconds.\n"
     ]
    }
   ],
   "source": [
    "tic()\n",
    "\n",
    "for search_word in search_words:\n",
    "\n",
    "    item_count = 0\n",
    "    current_page = 1\n",
    "    search_result_num = 0\n",
    "\n",
    "    # =======================================================================================\n",
    "    # 검색 결과 리스트 페이지 별 확인\n",
    "    \n",
    "    while True:\n",
    "        search_link = f'https://www.saramin.co.kr/zf_user/search/recruit'\\\n",
    "            + f'?search_area=main'\\\n",
    "            + f'&search_done=y'\\\n",
    "            + f'&search_optional_item=n'\\\n",
    "            + f'&searchType=search'\\\n",
    "            + f'&recruitSort=relation'\\\n",
    "            + f'&searchword={search_word}'\\\n",
    "            + f'&recruitPage={current_page}'\\\n",
    "            + f'&recruitPageCount={page_view_items}'\\\n",
    "            + f'&company_cd={company_cd}'\\\n",
    "            + f'&mainSearch=y'\n",
    "        response = requests.get(search_link, headers=request_headers, verify=False)\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        dom = etree.HTML(str(soup))\n",
    "        \n",
    "        # =======================================================================================\n",
    "        # 종료조건 - 검색 결과가 없으면 종료\n",
    "        \n",
    "        try:\n",
    "            num_str = dom.xpath('//*[@id=\"recruit_info\"]/div[1]/span')[0].text    # 검색단어 리스트 별 검색 결과 개수\n",
    "            search_result_num = int(re.sub(r'[^0-9]', '', num_str))\n",
    "        except:\n",
    "            break\n",
    "        finally:\n",
    "            if current_page == 1:\n",
    "                print(f'{search_word}: {search_result_num}')\n",
    "\n",
    "        # =======================================================================================\n",
    "        # 채용정보 리스트\n",
    "        page_items = len(soup.find_all('h2', attrs={'class': 'job_tit'}))\n",
    "\n",
    "        for i in range(1, page_items+1):\n",
    "            elements = soup.select(f'div.content > div:nth-child({i})')[0]\n",
    "\n",
    "            # ==============================================\n",
    "            # 회사명 필터링 \n",
    "            company_str = elements.find('a', attrs={'class': 'track_event data_layer'}).text\n",
    "            filtering_company_result = filtering_company_name(company_str)\n",
    "            if filtering_company_result[0] == 0:\n",
    "                continue\n",
    "            else:\n",
    "                company_str = filtering_company_result[1]\n",
    "\n",
    "            # ==============================================\n",
    "            # 채용공고명 필터링\n",
    "            posting_str = elements.find('a', attrs={'class': 'data_layer'})['title']\n",
    "            filtering_posting_result = filtering_posting_name(posting_str)\n",
    "            if filtering_posting_result[0] == 0:\n",
    "                continue\n",
    "            else:\n",
    "                # 채용공고 링크\n",
    "                posting_link = base_link_saram + elements.find('a', attrs={'class': 'data_layer'})['href']\n",
    "\n",
    "                # 회사 링크\n",
    "                company_link = base_link_saram + elements.find('a', attrs={'class': 'track_event data_layer'})['href']\n",
    "\n",
    "            # ==============================================\n",
    "            # Dictionary에 저장\n",
    "            save_dictionary(company_str, company_link, posting_str, posting_link)\n",
    "\n",
    "            item_count += 1\n",
    "        current_page += 1\n",
    "        \n",
    "print(\"--------------------------------------------\")\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e50235f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5425"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13f9a1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13580\n"
     ]
    }
   ],
   "source": [
    "nCnt = 0\n",
    "for i in job_group:\n",
    "    for j in job_group[i]:\n",
    "        nCnt += 1\n",
    "print(nCnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31a6539",
   "metadata": {},
   "source": [
    "### JSON 파일 쓰기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1b9454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON 파일 쓰기\n",
    "tf = open(file_path, 'w')\n",
    "json.dump(job_group, tf)\n",
    "tf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af43b062",
   "metadata": {},
   "source": [
    "### 잡코리아"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eff33be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "컴퓨터비전: 450\n",
      "COMPUTER VISION: 97\n",
      "영상처리: 667\n",
      "IMAGE PROCESSING: 39\n",
      "딥러닝: 697\n",
      "DEEP LEARNING: 133\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='www.jobkorea.co.kr', port=443): Max retries exceeded with url: /Search/?stext=%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D&tabType=recruit&Page_No=30 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002C0665B2FD0>: Failed to establish a new connection: [WinError 10060] 연결된 구성원으로부터 응답이 없어 연결하지 못했거나, 호스트로부터 응답이 없어 연결이 끊어졌습니다'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\hackerrank\\lib\\site-packages\\urllib3\\connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     conn \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[0;32m    175\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dns_host, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kw\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hackerrank\\lib\\site-packages\\urllib3\\util\\connection.py:95\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m socket\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgetaddrinfo returns an empty list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hackerrank\\lib\\site-packages\\urllib3\\util\\connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 85\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sock\n",
      "\u001b[1;31mTimeoutError\u001b[0m: [WinError 10060] 연결된 구성원으로부터 응답이 없어 연결하지 못했거나, 호스트로부터 응답이 없어 연결이 끊어졌습니다",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\hackerrank\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hackerrank\\lib\\site-packages\\urllib3\\connectionpool.py:386\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 386\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hackerrank\\lib\\site-packages\\urllib3\\connectionpool.py:1042\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[1;32m-> 1042\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hackerrank\\lib\\site-packages\\urllib3\\connection.py:358\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;66;03m# Add certificate verification\u001b[39;00m\n\u001b[1;32m--> 358\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    359\u001b[0m     hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hackerrank\\lib\\site-packages\\urllib3\\connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m e\n\u001b[0;32m    188\u001b[0m     )\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x000002C0665B2FD0>: Failed to establish a new connection: [WinError 10060] 연결된 구성원으로부터 응답이 없어 연결하지 못했거나, 호스트로부터 응답이 없어 연결이 끊어졌습니다",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\hackerrank\\lib\\site-packages\\requests\\adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunked:\n\u001b[1;32m--> 489\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hackerrank\\lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    785\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[1;32m--> 787\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    790\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hackerrank\\lib\\site-packages\\urllib3\\util\\retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[1;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[0;32m    594\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='www.jobkorea.co.kr', port=443): Max retries exceeded with url: /Search/?stext=%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D&tabType=recruit&Page_No=30 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002C0665B2FD0>: Failed to establish a new connection: [WinError 10060] 연결된 구성원으로부터 응답이 없어 연결하지 못했거나, 호스트로부터 응답이 없어 연결이 끊어졌습니다'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m(search_loop):\n\u001b[0;32m     13\u001b[0m     search_link \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.jobkorea.co.kr/Search/\u001b[39m\u001b[38;5;124m'\u001b[39m \\\n\u001b[0;32m     14\u001b[0m                 \u001b[38;5;241m+\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m?stext=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msearch_word\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \\\n\u001b[0;32m     15\u001b[0m                 \u001b[38;5;241m+\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m&tabType=recruit&Page_No=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_page\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 17\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43msearch_link\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     html \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m     19\u001b[0m     soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(html, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hackerrank\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hackerrank\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hackerrank\\lib\\site-packages\\requests\\sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    582\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    584\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    585\u001b[0m }\n\u001b[0;32m    586\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 587\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hackerrank\\lib\\site-packages\\requests\\sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    698\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    700\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    703\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\hackerrank\\lib\\site-packages\\requests\\adapters.py:565\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[0;32m    562\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[0;32m    563\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m--> 565\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='www.jobkorea.co.kr', port=443): Max retries exceeded with url: /Search/?stext=%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D&tabType=recruit&Page_No=30 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002C0665B2FD0>: Failed to establish a new connection: [WinError 10060] 연결된 구성원으로부터 응답이 없어 연결하지 못했거나, 호스트로부터 응답이 없어 연결이 끊어졌습니다'))"
     ]
    }
   ],
   "source": [
    "# 잡코리아\n",
    "# 저장된 키워드 별 검색\n",
    "\n",
    "tic()\n",
    "for search_word in search_words:\n",
    "\n",
    "    item_count = 0\n",
    "    current_page = 1\n",
    "    \n",
    "    # 검색 결과 리스트 페이지 별 확인\n",
    "    search_loop = True\n",
    "    while(search_loop):\n",
    "        search_link = f'https://www.jobkorea.co.kr/Search/' \\\n",
    "                    +f'?stext={search_word}' \\\n",
    "                    +f'&tabType=recruit&Page_No={current_page}'\n",
    "\n",
    "        response = requests.get(search_link, headers=request_headers, verify=False)\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        # =======================================================================================\n",
    "        # 채용정보 리스트\n",
    "        page_items = len(soup.find_all('a', attrs={'class': 'title dev_view'}))\n",
    "        \n",
    "        if page_items == 0:\n",
    "            search_loop = False\n",
    "        else:\n",
    "            for i in range(0, page_items):\n",
    "\n",
    "                # ==============================================\n",
    "                # 회사명 필터링 \n",
    "                company_str = soup.find_all('a', attrs={'class': 'name dev_view'})[i].text\n",
    "                filtering_company_result = filtering_company_name(company_str)\n",
    "                \n",
    "                if filtering_company_result[0] == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    company_str = filtering_company_result[1]\n",
    "                \n",
    "                \n",
    "                # ==============================================\n",
    "                # 채용공고명 필터링\n",
    "                posting_str = soup.find_all('a', attrs={'class': 'title dev_view'})[i].text\n",
    "                posting_str = posting_str.replace('\\r\\n', '')\n",
    "                posting_str = posting_str.strip()\n",
    "                \n",
    "                filtering_posting_result = filtering_posting_name(posting_str)\n",
    "                \n",
    "                if filtering_posting_result[0] == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    # 채용공고 링크\n",
    "                    posting_link = base_link_korea + soup.find_all('a', attrs={'class': 'title dev_view'})[i]['href']\n",
    "\n",
    "                    # 회사 링크\n",
    "                    company_link = base_link_korea + soup.find_all('a', attrs={'class': 'name dev_view'})[i]['href']\n",
    "                    \n",
    "                # ==============================================\n",
    "                # Dictionary에 저장\n",
    "                save_dictionary(company_str, company_link, posting_str, posting_link)\n",
    "                \n",
    "                item_count += 1\n",
    "        current_page += 1\n",
    "    print(f'{search_word}: {item_count}')\n",
    "    \n",
    "print(\"--------------------------------------------\")\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50559ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(job_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c00a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "nCnt = 0\n",
    "for i in job_group:\n",
    "    for j in job_group[i]:\n",
    "        nCnt += 1\n",
    "print(nCnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abba220b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON 파일 쓰기\n",
    "tf = open(file_path, 'w')\n",
    "json.dump(job_group, tf)\n",
    "tf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb812a22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019232c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52011d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df04967a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a369262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1ac6d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061b6b35",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # JSON 파일 쓰기\n",
    "# tf = open(file_path, 'w')\n",
    "# json.dump(job_group, tf)\n",
    "# tf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996ed0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # JSON 파일 불러오기\n",
    "# with open(file_path, 'r') as file:\n",
    "#     job_group = json.load(file)\n",
    "# print(len(job_group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255b3732",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackerrank",
   "language": "python",
   "name": "hackerrank"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
