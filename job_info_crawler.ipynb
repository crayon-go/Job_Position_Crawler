{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efc08c0f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "import threading\n",
    "import queue\n",
    "import random\n",
    "import datetime\n",
    "import os\n",
    "import urllib3\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from urllib.error import URLError, HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "from config.assistant import *\n",
    "from config.site_config import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "request_headers = {\n",
    "    'User-Agent': ('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
    "                   '(KHTML, like Gecko) Chrome/68.0.3440.75 Safari/537.36'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07f7721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_group = {}\n",
    "\n",
    "with open(filter_list_company_name_path) as f:\n",
    "    filter_list_company_name = f.read().splitlines()\n",
    "with open(filter_list_company_name_part_path) as f:\n",
    "    filter_list_company_name_part = f.read().splitlines()\n",
    "\n",
    "with open(filter_list_posting_region_path) as f:\n",
    "    filter_list_posting_region = f.read().splitlines()\n",
    "with open(filter_list_posting_name_part_path) as f:\n",
    "    filter_list_posting_name_part = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f630935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dictionary(job_company, company_link, posting_str, posting_link):\n",
    "    global job_group\n",
    "    \n",
    "    # 신규 회사명 인입\n",
    "    if not job_company in job_group:    \n",
    "        job_group[job_company] = []\n",
    "    \n",
    "    for company in job_group[job_company]:\n",
    "        if company['title'] == posting_str:    # 채용공고명 - 중복\n",
    "            break\n",
    "    else:\n",
    "        job_group[job_company].append({'company': job_company, \\\n",
    "                                       'company_link': company_link, \\\n",
    "                                       'title': posting_str, \\\n",
    "                                       'title_link': posting_link, \\\n",
    "                                       'title_idx': len(job_group[job_company]), \\\n",
    "                                       'input_date': datetime.date.today().isoformat(), \\\n",
    "                                       'status': 'wait'\n",
    "                                      })\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e7d4e8",
   "metadata": {},
   "source": [
    "### 회사명 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07d6187e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering_company_name(job_company):\n",
    "\n",
    "    # 회사명 - 특정 단어 제거\n",
    "    for remove_word in remove_words:\n",
    "        if remove_word in job_company:\n",
    "            job_company = job_company.replace(remove_word, '')\n",
    "            \n",
    "    # 회사명 - ()괄호 안의 모든 단어 제거\n",
    "    company_re = re.search('\\(.*\\)', job_company)\n",
    "    if company_re:\n",
    "        str_filtering = job_company[company_re.span()[0]:company_re.span()[1]]\n",
    "        job_company = job_company.replace(str_filtering, '')\n",
    "        \n",
    "    # 회사명 - 완전히 일치하는 회사명 리스트 필터링\n",
    "    if job_company in filter_list_company_name:\n",
    "        return 0, \"none\"\n",
    "    \n",
    "    # 회사명 - 특정 단어가 포함되어 있는 회사 필터링\n",
    "    for remove_word in filter_list_company_name_part:\n",
    "        if remove_word in job_company:\n",
    "            return 0, \"none\"\n",
    "\n",
    "    return 1, job_company"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80008f12",
   "metadata": {},
   "source": [
    "### 채용공고명 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d40a54be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering_posting_name(posting_str):\n",
    "\n",
    "    # 지역명이 포함되는 경우 탈락\n",
    "    for remove_word in filter_list_posting_region:\n",
    "        if remove_word in posting_str:\n",
    "            return 0, \"none\"\n",
    "\n",
    "    # 특정 단어가 포함되는 경우 탈락\n",
    "    for remove_word in filter_list_posting_name_part:\n",
    "        if remove_word in posting_str:\n",
    "            return 0, \"none\"\n",
    "\n",
    "    return 1, posting_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5e5d0c",
   "metadata": {},
   "source": [
    "### 사람인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee70547b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "컴퓨터비전: 1298\n",
      "COMPUTER VISION: 1127\n",
      "영상처리: 1077\n",
      "IMAGE PROCESSING: 288\n",
      "딥러닝: 1188\n",
      "DEEP LEARNING: 1188\n",
      "머신러닝: 1588\n",
      "MACHINE LEARNING: 1582\n",
      "이미지인식: 237\n",
      "IMAGE RECOGNITION: 21\n",
      "이미지분석: 777\n",
      "IMAGE ANALYSIS: 28\n",
      "VISION AI: 823\n",
      "OPENCV: 258\n",
      "--------------------------------------------\n",
      "Elapsed time is 647.4740600585938 seconds.\n"
     ]
    }
   ],
   "source": [
    "tic()\n",
    "\n",
    "for search_word in search_words:\n",
    "\n",
    "    item_count = 0\n",
    "    current_page = 1\n",
    "    search_result_num = 0\n",
    "\n",
    "    # =======================================================================================\n",
    "    # 검색 결과 리스트 페이지 별 확인\n",
    "    \n",
    "    while True:\n",
    "        search_link = f'https://www.saramin.co.kr/zf_user/search/recruit'\\\n",
    "            + f'?search_area=main'\\\n",
    "            + f'&search_done=y'\\\n",
    "            + f'&search_optional_item=n'\\\n",
    "            + f'&searchType=search'\\\n",
    "            + f'&recruitSort=relation'\\\n",
    "            + f'&searchword={search_word}'\\\n",
    "            + f'&recruitPage={current_page}'\\\n",
    "            + f'&recruitPageCount={page_view_items}'\\\n",
    "            + f'&company_cd={company_cd}'\\\n",
    "            + f'&mainSearch=y'\n",
    "        response = requests.get(search_link, headers=request_headers, verify=False)\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        dom = etree.HTML(str(soup))\n",
    "        \n",
    "        # =======================================================================================\n",
    "        # 종료조건 - 검색 결과가 없으면 종료\n",
    "        \n",
    "        try:\n",
    "            num_str = dom.xpath('//*[@id=\"recruit_info\"]/div[1]/span')[0].text    # 검색단어 리스트 별 검색 결과 개수\n",
    "            search_result_num = int(re.sub(r'[^0-9]', '', num_str))\n",
    "        except:\n",
    "            break\n",
    "        finally:\n",
    "            if current_page == 1:\n",
    "                print(f'{search_word}: {search_result_num}')\n",
    "\n",
    "        # =======================================================================================\n",
    "        # 채용정보 리스트\n",
    "        page_items = len(soup.find_all('h2', attrs={'class': 'job_tit'}))\n",
    "\n",
    "        for i in range(1, page_items+1):\n",
    "            elements = soup.select(f'div.content > div:nth-child({i})')[0]\n",
    "\n",
    "            # ==============================================\n",
    "            # 회사명 필터링 \n",
    "            company_str = elements.find('a', attrs={'class': 'track_event data_layer'}).text\n",
    "            filtering_company_result = filtering_company_name(company_str)\n",
    "            if filtering_company_result[0] == 0:\n",
    "                continue\n",
    "            else:\n",
    "                company_str = filtering_company_result[1]\n",
    "\n",
    "            # ==============================================\n",
    "            # 채용공고명 필터링\n",
    "            posting_str = elements.find('a', attrs={'class': 'data_layer'})['title']\n",
    "            filtering_posting_result = filtering_posting_name(posting_str)\n",
    "            if filtering_posting_result[0] == 0:\n",
    "                continue\n",
    "            else:\n",
    "                # 채용공고 링크\n",
    "                posting_link = base_link_saram + elements.find('a', attrs={'class': 'data_layer'})['href']\n",
    "\n",
    "                # 회사 링크\n",
    "                company_link = base_link_saram + elements.find('a', attrs={'class': 'track_event data_layer'})['href']\n",
    "\n",
    "            # ==============================================\n",
    "            # Dictionary에 저장\n",
    "            save_dictionary(company_str, company_link, posting_str, posting_link)\n",
    "\n",
    "            item_count += 1\n",
    "        current_page += 1\n",
    "        \n",
    "print(\"--------------------------------------------\")\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e50235f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5874"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13f9a1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13280\n"
     ]
    }
   ],
   "source": [
    "nCnt = 0\n",
    "for i in job_group:\n",
    "    for j in job_group[i]:\n",
    "        nCnt += 1\n",
    "print(nCnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af43b062",
   "metadata": {},
   "source": [
    "### 잡코리아"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eff33be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "컴퓨터비전: 624\n",
      "COMPUTER VISION: 102\n",
      "영상처리: 749\n",
      "IMAGE PROCESSING: 54\n",
      "딥러닝: 866\n",
      "DEEP LEARNING: 158\n",
      "머신러닝: 1204\n",
      "MACHINE LEARNING: 1207\n",
      "이미지인식: 84\n",
      "IMAGE RECOGNITION: 21\n",
      "이미지분석: 1008\n",
      "IMAGE ANALYSIS: 19\n",
      "VISION AI: 225\n",
      "OPENCV: 133\n",
      "--------------------------------------------\n",
      "Elapsed time is 573.2893731594086 seconds.\n"
     ]
    }
   ],
   "source": [
    "# 잡코리아\n",
    "# 저장된 키워드 별 검색\n",
    "\n",
    "tic()\n",
    "for search_word in search_words:\n",
    "\n",
    "    item_count = 0\n",
    "    current_page = 1\n",
    "    \n",
    "    # 검색 결과 리스트 페이지 별 확인\n",
    "    search_loop = True\n",
    "    while(search_loop):\n",
    "        search_link = f'https://www.jobkorea.co.kr/Search/' \\\n",
    "                    +f'?stext={search_word}' \\\n",
    "                    +f'&tabType=recruit&Page_No={current_page}'\n",
    "\n",
    "        response = requests.get(search_link, headers=request_headers, verify=False)\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        # =======================================================================================\n",
    "        # 채용정보 리스트\n",
    "        page_items = len(soup.find_all('a', attrs={'class': 'title dev_view'}))\n",
    "        \n",
    "        if page_items == 0:\n",
    "            search_loop = False\n",
    "        else:\n",
    "            for i in range(0, page_items):\n",
    "\n",
    "                # ==============================================\n",
    "                # 회사명 필터링 \n",
    "                company_str = soup.find_all('a', attrs={'class': 'name dev_view'})[i].text\n",
    "                filtering_company_result = filtering_company_name(company_str)\n",
    "                \n",
    "                if filtering_company_result[0] == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    company_str = filtering_company_result[1]\n",
    "                \n",
    "                \n",
    "                # ==============================================\n",
    "                # 채용공고명 필터링\n",
    "                posting_str = soup.find_all('a', attrs={'class': 'title dev_view'})[i].text\n",
    "                posting_str = posting_str.replace('\\r\\n', '')\n",
    "                posting_str = posting_str.strip()\n",
    "                \n",
    "                filtering_posting_result = filtering_posting_name(posting_str)\n",
    "                \n",
    "                if filtering_posting_result[0] == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    # 채용공고 링크\n",
    "                    posting_link = base_link_korea + soup.find_all('a', attrs={'class': 'title dev_view'})[i]['href']\n",
    "\n",
    "                    # 회사 링크\n",
    "                    company_link = base_link_korea + soup.find_all('a', attrs={'class': 'name dev_view'})[i]['href']\n",
    "                    \n",
    "                # ==============================================\n",
    "                # Dictionary에 저장\n",
    "                save_dictionary(company_str, company_link, posting_str, posting_link)\n",
    "                \n",
    "                item_count += 1\n",
    "        current_page += 1\n",
    "    print(f'{search_word}: {item_count}')\n",
    "    \n",
    "print(\"--------------------------------------------\")\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50559ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5935"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81c00a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13536\n"
     ]
    }
   ],
   "source": [
    "nCnt = 0\n",
    "for i in job_group:\n",
    "    for j in job_group[i]:\n",
    "        nCnt += 1\n",
    "print(nCnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abba220b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb812a22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96304fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019232c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52011d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "061b6b35",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# JSON 파일 쓰기\n",
    "tf = open(file_path, 'w')\n",
    "json.dump(job_group, tf)\n",
    "tf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "996ed0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5811\n"
     ]
    }
   ],
   "source": [
    "# JSON 파일 불러오기\n",
    "with open(file_path, 'r') as file:\n",
    "    job_group = json.load(file)\n",
    "print(len(job_group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255b3732",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackerrank",
   "language": "python",
   "name": "hackerrank"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
