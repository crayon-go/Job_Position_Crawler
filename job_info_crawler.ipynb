{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efc08c0f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "import threading\n",
    "import queue\n",
    "import random\n",
    "import datetime\n",
    "import os\n",
    "import urllib3\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from urllib.error import URLError, HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "from config.assistant import *\n",
    "from config.site_config import *\n",
    "\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07f7721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_group = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f630935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dictionary(job_company, company_link, job_posting, posting_link):\n",
    "    global job_group\n",
    "    \n",
    "    # 신규 회사명 인입\n",
    "    if not job_company in job_group:    \n",
    "        job_group[job_company] = []\n",
    "    \n",
    "    for company in job_group[job_company]:\n",
    "        if company['title'] == job_posting:    # 채용공고명 - 중복\n",
    "            break\n",
    "    else:\n",
    "        job_group[job_company].append({'company': job_company, \\\n",
    "                                       'company_link': company_link, \\\n",
    "                                       'title': job_posting, \\\n",
    "                                       'title_link': posting_link, \\\n",
    "                                       'title_idx': len(job_group[job_company]), \\\n",
    "                                       'input_date': datetime.date.today().isoformat(), \\\n",
    "                                       'status': 'wait'\n",
    "                                      })\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07d6187e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering_company(job_company):\n",
    "    company_re = re.search('\\(.*\\)', job_company)\n",
    "    if company_re:\n",
    "        str_filtering = job_company[company_re.span()[0]:company_re.span()[1]]\n",
    "        job_company = job_company.replace(str_filtering, '')\n",
    "    job_company = job_company.replace('㈜', '')\n",
    "    job_company = job_company.replace('㈔', '')\n",
    "    job_company = job_company.replace('재)', '')\n",
    "    job_company = job_company.replace('주)', '')\n",
    "    job_company = job_company.replace(' ', '')\n",
    "    job_company = job_company.replace('\\n', '')\n",
    "    if job_company in company_filtering_list:\n",
    "        return 0, \"none\"\n",
    "\n",
    "    return 1, job_company\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5e5d0c",
   "metadata": {},
   "source": [
    "### 사람인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee70547b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "컴퓨터비전: 1208\n",
      "COMPUTER VISION: 1052\n",
      "영상처리: 1079\n",
      "IMAGE PROCESSING: 291\n",
      "딥러닝: 1188\n",
      "DEEP LEARNING: 1188\n",
      "머신러닝: 1507\n",
      "MACHINE LEARNING: 1500\n",
      "이미지인식: 211\n",
      "IMAGE RECOGNITION: 21\n",
      "이미지분석: 705\n",
      "IMAGE ANALYSIS: 29\n",
      "VISION AI: 777\n",
      "OPENCV: 247\n",
      "Elapsed time is 603.0929794311523 seconds.\n"
     ]
    }
   ],
   "source": [
    "# 사람인\n",
    "tic()\n",
    "for search_word in search_words:\n",
    "\n",
    "    item_count = 0\n",
    "    current_page = 1\n",
    "    \n",
    "    # 검색 결과 리스트 페이지 별 확인\n",
    "    search_loop = True\n",
    "    while(search_loop):\n",
    "        search_link = f'https://www.saramin.co.kr/zf_user/search/recruit'\\\n",
    "            + f'?search_area=main'\\\n",
    "            + f'&search_done=y'\\\n",
    "            + f'&search_optional_item=n'\\\n",
    "            + f'&searchType=search'\\\n",
    "            + f'&recruitSort=relation'\\\n",
    "            + f'&searchword={search_word}'\\\n",
    "            + f'&recruitPage={current_page}'\\\n",
    "            + f'&recruitPageCount={page_view_items}'\\\n",
    "            + f'&company_cd={company_cd}'\\\n",
    "            + f'&mainSearch=y'\n",
    "\n",
    "        response = requests.get(search_link, verify=False)\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        if len(soup.find_all('div', attrs={'class': 'info_no_result'})) == 1:\n",
    "            search_loop = False\n",
    "        else:\n",
    "            current_page += 1\n",
    "\n",
    "            page_items = len(soup.find_all('h2', attrs={'class': 'job_tit'}))\n",
    "\n",
    "            # 해당 페이지 리스트 (1 ~ 100)\n",
    "            for i in range(1, page_items+1):\n",
    "                elements = soup.select(f'div.content > div:nth-child({i})')[0]\n",
    "\n",
    "                # 회사명\n",
    "                job_company = elements.find('a', attrs={'class': 'track_event data_layer'}).text\n",
    "                filtering_result = filtering_company(job_company)\n",
    "                if filtering_result[0] == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    job_company = filtering_result[1]\n",
    "                    \n",
    "                # 채용공고명\n",
    "                job_posting = elements.find('a', attrs={'class': 'data_layer'})['title']\n",
    "\n",
    "                # 채용공고 링크\n",
    "                posting_link = base_link_saram + elements.find('a', attrs={'class': 'data_layer'})['href']\n",
    "\n",
    "                # 회사 링크\n",
    "                company_link = base_link_saram + elements.find('a', attrs={'class': 'track_event data_layer'})['href']\n",
    "\n",
    "                # Dictionary에 저장\n",
    "                save_dictionary(job_company, company_link, job_posting, posting_link)\n",
    "                \n",
    "                item_count += 1\n",
    "                \n",
    "    print(f'{search_word}: {item_count}')\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e50235f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4915"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13f9a1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10015\n"
     ]
    }
   ],
   "source": [
    "nCnt = 0\n",
    "for i in job_group:\n",
    "    for j in job_group[i]:\n",
    "        nCnt += 1\n",
    "print(nCnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af43b062",
   "metadata": {},
   "source": [
    "### 잡코리아"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eff33be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "컴퓨터비전: 1165\n",
      "COMPUTER VISION: 117\n",
      "영상처리: 1171\n",
      "IMAGE PROCESSING: 60\n",
      "딥러닝: 1075\n",
      "DEEP LEARNING: 181\n",
      "머신러닝: 1747\n",
      "MACHINE LEARNING: 1749\n",
      "이미지인식: 125\n",
      "IMAGE RECOGNITION: 27\n",
      "이미지분석: 2312\n",
      "IMAGE ANALYSIS: 28\n",
      "VISION AI: 252\n",
      "OPENCV: 149\n",
      "Elapsed time is 556.5792679786682 seconds.\n"
     ]
    }
   ],
   "source": [
    "# 잡코리아\n",
    "# 저장된 키워드 별 검색\n",
    "\n",
    "tic()\n",
    "for search_word in search_words:\n",
    "\n",
    "    item_count = 0\n",
    "    current_page = 1\n",
    "    \n",
    "    # 검색 결과 리스트 페이지 별 확인\n",
    "    search_loop = True\n",
    "    while(search_loop):\n",
    "        search_link = f'https://www.jobkorea.co.kr/Search/' \\\n",
    "                    +f'?stext={search_word}' \\\n",
    "                    +f'&tabType=recruit&Page_No={current_page}'\n",
    "\n",
    "        response = requests.get(search_link, verify=False)\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        page_items = len(soup.find_all('a', attrs={'class': 'title dev_view'}))\n",
    "        \n",
    "        if page_items == 0:\n",
    "            search_loop = False\n",
    "        else:\n",
    "            for i in range(0, page_items):\n",
    "                # 회사명\n",
    "                job_company = soup.find_all('a', attrs={'class': 'name dev_view'})[i].text\n",
    "                filtering_result = filtering_company(job_company)\n",
    "                if filtering_result[0] == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    job_company = filtering_result[1]\n",
    "                \n",
    "                # 회사 링크\n",
    "                company_link = base_link_korea + soup.find_all('a', attrs={'class': 'name dev_view'})[i]['href']\n",
    "                \n",
    "                # 채용공고\n",
    "                job_posting = soup.find_all('a', attrs={'class': 'title dev_view'})[i].text\n",
    "                job_posting = job_posting.replace('\\r\\n', '')\n",
    "                job_posting = job_posting.strip()\n",
    "\n",
    "                # 채용공고 링크\n",
    "                posting_link = base_link_korea + soup.find_all('a', attrs={'class': 'title dev_view'})[i]['href']\n",
    "\n",
    "                # Dictionary에 저장\n",
    "                save_dictionary(job_company, company_link, job_posting, posting_link)\n",
    "                \n",
    "                item_count += 1\n",
    "        current_page += 1\n",
    "    print(f'{search_word}: {item_count}')\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50559ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5146"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81c00a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10765\n"
     ]
    }
   ],
   "source": [
    "nCnt = 0\n",
    "for i in job_group:\n",
    "    for j in job_group[i]:\n",
    "        nCnt += 1\n",
    "print(nCnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abba220b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb812a22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96304fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019232c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52011d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "061b6b35",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# JSON 파일 쓰기\n",
    "tf = open(file_path, 'w')\n",
    "json.dump(job_group, tf)\n",
    "tf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "996ed0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4674\n"
     ]
    }
   ],
   "source": [
    "# JSON 파일 불러오기\n",
    "with open(file_path, 'r') as file:\n",
    "    job_group = json.load(file)\n",
    "print(len(job_group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1501876",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackerrank",
   "language": "python",
   "name": "hackerrank"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
